# Electrical-Results-ETL
A very simple ETL pipeline with the purpose of routinely ingesting .txt files containing raw test data.

The code within this repo is intended as a proof of concept and as an educational project within which to become familiar with ETL tools and processes.

![ETL](https://user-images.githubusercontent.com/45105631/155688579-e09cafd9-cd9d-484b-b0e9-63fad7b31201.PNG)

Test results are periodically written to txt files within a known directory - these results contain timestamped resistances, generated by Keithley instruments.
This ETL process is designed to check for completed test files, extract their contents, calculate metrics of interest and store these in a database. Further analysis of the generated data can be done *via* the dashboard.
 
 ## Airflow Web UI
 
 Below is an example of the DAG (directed acyclic graph) being triggered manually (usually scheduled to run every 15 minutes).
 
![Airflow gif](https://user-images.githubusercontent.com/45105631/155702416-788043aa-1224-422b-9220-be4b6de20a41.gif)

From the Graph View we can see the DAG running through each task, according to their dependancies.

## Pipeline Tasks

1. **Start:** DAG begins.
2. **get_files:** A series of checks are performed to determine if a file contains a complete set of test results. Returns any results files that are eligible for processing.
3. **any_files_branch:** A list of eligible files are pulled in *via* Airflow's XCom feature. Path to take is determined by the number of eligible files.
4. **process_files:** Eligible files are ingested - raw data is cleaned and useful metrics are calculated. Results are stored in the database and the raw txt file is relocated.
5. **no_files:** Only runs if there are no eligible files for process.
